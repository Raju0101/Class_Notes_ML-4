{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36235a83-ecae-458d-86b2-58032a722fd9",
   "metadata": {},
   "source": [
    "# AssQ 1-May-ML-Clustering-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02271a25-10a5-454b-be0c-59d2cf502fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123d3fd-28ea-4905-bbc7-34b2dca5c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "Creating a basic contingency table. To create a contingency table of the data in the var1 \n",
    "column cross-classified with the data in the var2 column, choose the Stat > Tables > Contingency >\n",
    "With Data menu option. Select var1 as the Row variable, choose var2 as the Column variable, and click Compute!.\n",
    "\n",
    "A contingency table summarizes information of multiple discrete random variables.\n",
    "An example of the contingency table : x is the random variable\n",
    "representing students' likes and dislikes of probability and statistics, \n",
    "while y is the random variable representing their drowsiness during the lecture.\n",
    "\n",
    "Contingency tables are used to describe data.\n",
    "\n",
    "Contingency tables classify outcomes for one variable in rows and the other in columns. \n",
    "The values at the row and column intersections are frequencies for each unique combination of the two variables. \n",
    "Use contingency tables to understand the relationship between categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97836fc-76e1-4df2-92d6-495dd24def11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f495bf4-062f-4912-899c-726d9c3d8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in \n",
    "certain situations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ae69c-723f-4e1d-9bf7-f1fa5f0f6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "The pair confusion matrix computes a 2 by 2 similarity matrix between two clusterings by considering \n",
    "all pairs of samples and counting pairs that are assigned into the same or\n",
    "into different clusters under the true and predicted clusterings.\n",
    "\n",
    "Confusion Matrix is a classification matrix used in supervised learning.\n",
    "Confusion matrix is helpful when one wants to evaluate the performance of a classifier or Machine Learning algorithm. \n",
    "It gives a good comparison of the predicted and real/actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5d97a-71cf-46a4-bf09-d481ed5d0582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c50cab3-784b-4aa0-a7dc-a030b7210fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically \n",
    "used to evaluate the performance of language models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57307e84-5ca0-40dc-8949-f69a238123fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extrinsic evaluation is the best way to evaluate the performance of a language model by embedding\n",
    "it in an application and measuring how much the application improves.\n",
    "It is an end-to-end  evaluation where we can understand \n",
    "if a particular improvement in a component is really going to help the task at hand.\n",
    "\n",
    "Perplexity is the multiplicative inverse of the probability assigned to the test set by the language model,\n",
    "normalized by the number of words in the test set. If a language model can predict unseen words\n",
    "from the test set, i.e., the P(a sentence from a test set)\n",
    "is highest; then such a language model is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5b1d4-ce62-4284-8e83-230f32f785dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dc52d-a2f2-49c8-8ff8-13a118b49109",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an \n",
    "extrinsic measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59e07f-0794-4196-b194-2daab18d77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "In machine learning, the performance of a classifier depends on both the classifier \n",
    "model and the separability/complexity of datasets. To quantitatively measure the separability of datasets,\n",
    "we create an intrinsic measure -- the Distance-based Separability Index (DSI),\n",
    "which is independent of the classifier model.\n",
    "\n",
    "Intrinsic evaluation methods assess the quality of the summarization output according to certain criteria,\n",
    "such as readability, comprehensiveness, accuracy, and relevancy.\n",
    "Output summaries are often rated by users or compared with a gold standard, typically hand-crafted by humans.\n",
    "\n",
    "Extrinsic evaluation of word vectors is the evaluation of a set of word vectors generated\n",
    "by an embedding technique on the real task at hand. \n",
    "These tasks are typically elaborate and slow to compute.\n",
    "\n",
    "In an intrinsic evaluation, quality of NLP systems outputs is evaluated against pre-determined ground\n",
    "truth (reference text) whereas an extrinsic evaluation is aimed at evaluating systems outputs \n",
    "based on their impact on the performance of other NLP systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6ac40-7ebe-4ac4-9814-ee2be76c3cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1be9a-fa06-47ac-a364-fc7c68091630",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify \n",
    "strengths and weaknesses of a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70636d-5a40-4e6a-953b-7f09e31ca9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "It evaluates the performance of the classification models, when they make predictions on test data, \n",
    "and tells how good our classification model is. It not only tells the error made by the classifiers\n",
    "but also the type of errors such as it is either type-I or type-II error.\n",
    "\n",
    "A confusion matrix represents the prediction summary in matrix form.\n",
    "It shows how many prediction are correct and incorrect per class. \n",
    "It helps in understanding the classes that are being confused by model as other class.\n",
    "\n",
    "Confusion matrices can help with side-by-side comparisons of different classification methods.\n",
    "You can see not only how accurate one model is over the other, but also see more granularly \n",
    "how a model does in sensitivity or specificity,\n",
    "as those might be more important factors than general accuracy itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761639f8-b9a7-429d-9cf1-fd0e8642f21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319afe9-bc3e-4e2a-91bd-f406dcfcb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised \n",
    "learning algorithms, and how can they be interpreted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed1696-f4f9-4ed9-b41a-3e95312f8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "In general, intrinsic methods evaluate a clustering by examining how well the clusters are separated \n",
    "and how compact the clusters are.\n",
    "Many intrinsic methods have the advantage of a similarity metric between objects in the data set.\n",
    "\n",
    "In an intrinsic evaluation, quality of NLP systems outputs is evaluated against pre-determined \n",
    "ground truth (reference text) whereas an extrinsic evaluation is aimed at evaluating systems \n",
    "outputs based on their impact on the performance of other NLP systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89832be6-fd82-4c45-be8e-e4224fe9c86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffd856-82b7-4c60-8b9e-f23469d5580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and \n",
    "how can these limitations be addressed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d7f84-77b2-4a3f-9924-3ad89eb8bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "In general, the main disadvantage of accuracy is that it masks the issue of class imbalance. \n",
    "For example if the data contains only 10% of positive instances, a majority baseline \n",
    "classifier which always assigns the negative \n",
    "label would reach 90% accuracy since it would correctly predict 90% instances.\n",
    "\n",
    "It hides the detail you need to better understand the performance of your classification model.\n",
    "\n",
    "Some of the methods that can be applied on the data side are as follows:\n",
    "Method 1: Acquire more data.\n",
    "Method 2: Missing value treatment.\n",
    "Method 3: Outlier treatment.\n",
    "Method 4: Feature engineering.\n",
    "Method 1: Hyperparameter tuning.\n",
    "Method 2: Applying different models.\n",
    "Method 3: Ensembling methods.\n",
    "Method 4: Cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af3917-dbfa-4f4d-bc43-a59d428cdaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448815c3-1d55-43b3-a123-215e3b3e9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    ".....................The End............................"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
